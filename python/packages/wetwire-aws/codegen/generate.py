"""
Stage 3: Generate Python dataclasses from intermediate format.

Reads the parsed intermediate schema and generates Python source files
for each AWS service, including enum constants from botocore.
"""

import argparse
import json
import os
import subprocess
import sys
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import UTC, datetime
from pathlib import Path

from codegen.config import GENERATOR_VERSION, RESOURCES_DIR, SPECS_DIR
from codegen.intermediate import (
    IntermediateSchema,
    NestedTypeDef,
    PropertyDef,
    ResourceDef,
)

# Use all available CPU cores for parallel generation
NUM_WORKERS = os.cpu_count() or 4


# Mapping from CloudFormation service names to botocore service names
CF_TO_BOTOCORE_SERVICE = {
    "lambda_": "lambda",
    "apigateway": "apigateway",
    "apigatewayv2": "apigatewayv2",
    "applicationautoscaling": "application-autoscaling",
    "autoscaling": "autoscaling",
    "certificatemanager": "acm",
    "cloudfront": "cloudfront",
    "cloudwatch": "cloudwatch",
    "codebuild": "codebuild",
    "codepipeline": "codepipeline",
    "cognito": "cognito-idp",
    "dynamodb": "dynamodb",
    "ec2": "ec2",
    "ecr": "ecr",
    "ecs": "ecs",
    "efs": "efs",
    "elasticache": "elasticache",
    "elasticbeanstalk": "elasticbeanstalk",
    "elasticloadbalancing": "elb",
    "elasticloadbalancingv2": "elbv2",
    "events": "events",
    "iam": "iam",
    "kinesis": "kinesis",
    "kms": "kms",
    "logs": "logs",
    "rds": "rds",
    "redshift": "redshift",
    "route53": "route53",
    "s3": "s3",
    "secretsmanager": "secretsmanager",
    "ses": "ses",
    "sns": "sns",
    "sqs": "sqs",
    "ssm": "ssm",
    "stepfunctions": "stepfunctions",
    "wafv2": "wafv2",
}


def generate_file_header(
    service: str,
    cf_spec_version: str,
    generator_version: str,
) -> str:
    """Generate the file header with version info."""
    timestamp = datetime.now(UTC).strftime("%Y-%m-%dT%H:%M:%SZ")
    return f'''"""
AWS {service.upper()} CloudFormation resources.

Generated:
  Source: CloudFormation Spec {cf_spec_version}
  Generator: {generator_version}
  Date: {timestamp}

DO NOT EDIT - This file is generated by wetwire-aws codegen.
To regenerate: python -m wetwire_aws.codegen.generate
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, ClassVar

from wetwire_aws.base import CloudFormationResource, PropertyType

'''


def python_type_for_property(prop: PropertyDef) -> str:
    """Get the Python type annotation for a property."""
    base_type = prop.type

    # Handle common cases
    if base_type in ("str", "int", "float", "bool"):
        return base_type

    if base_type.startswith("list[") or base_type.startswith("dict["):
        return base_type

    if base_type == "list":
        if prop.item_type:
            return f"list[{prop.item_type}]"
        return "list[Any]"

    if base_type == "dict":
        if prop.item_type:
            return f"dict[str, {prop.item_type}]"
        return "dict[str, Any]"

    # It's a nested type
    if prop.nested_type:
        return prop.nested_type

    return "Any"


def get_property_type_signature(nested: NestedTypeDef) -> str:
    """Get a signature string for a PropertyType to detect duplicates."""
    if not nested.properties:
        return ""
    props = sorted((p.name, python_type_for_property(p)) for p in nested.properties)
    return str(props)


def generate_property_type(nested: NestedTypeDef) -> str:
    """Generate a PropertyType class for a nested structure."""
    lines = []

    # Class definition
    lines.append("@dataclass")
    lines.append(f"class {nested.name}(PropertyType):")

    # Skip URL-only docstrings to reduce file size
    # Documentation URLs can be derived from class name if needed

    if not nested.properties:
        lines.append("    pass")
        return "\n".join(lines)

    # Generate properties - all optional to avoid dataclass inheritance issues
    for prop in nested.properties:
        python_type = python_type_for_property(prop)

        # All fields are optional to avoid dataclass inheritance issues
        if python_type.startswith("list"):
            lines.append(
                f"    {prop.name}: {python_type} = field(default_factory=list)"
            )
        elif python_type.startswith("dict"):
            lines.append(
                f"    {prop.name}: {python_type} = field(default_factory=dict)"
            )
        else:
            lines.append(f"    {prop.name}: {python_type} | None = None")

    return "\n".join(lines)


def generate_enum_class(enum_name: str, enum_data: dict) -> str:
    """Generate a string constants class for an enum."""
    lines = []
    lines.append(f"class {enum_name}:")

    values = enum_data.get("values", [])
    if not values:
        lines.append("    pass")
        return "\n".join(lines)

    for val in values:
        name = val["name"]
        value = val["value"]
        # Escape quotes in value
        escaped_value = value.replace('"', '\\"')
        lines.append(f'    {name} = "{escaped_value}"')

    return "\n".join(lines)


def load_enums_for_service(service: str) -> dict[str, dict]:
    """Load enum definitions for a service from enums.json."""
    enums_path = SPECS_DIR / "enums.json"
    if not enums_path.exists():
        return {}

    try:
        all_enums = json.loads(enums_path.read_text())
        services = all_enums.get("services", {})

        # Try direct match first
        if service in services:
            return services[service]

        # Try botocore service name mapping
        botocore_name = CF_TO_BOTOCORE_SERVICE.get(service, service)
        if botocore_name in services:
            return services[botocore_name]

        return {}
    except Exception:
        return {}


def get_all_enums_for_service(
    service: str, all_enums: dict[str, dict]
) -> list[tuple[str, dict]]:
    """Get all enums for a service."""
    return [(name, data) for name, data in sorted(all_enums.items())]


def generate_resource_class(resource: ResourceDef, nested_types: set[str]) -> str:
    """Generate a CloudFormationResource class."""
    lines = []

    # Class definition
    lines.append("@dataclass")
    lines.append(f"class {resource.name}(CloudFormationResource):")

    # Docstring
    doc_lines = [f'"""{resource.name} resource.']
    if resource.documentation:
        doc_lines.append("")
        doc_lines.append(resource.documentation)
    doc_lines.append("")
    doc_lines.append(f"CloudFormation type: {resource.full_type}")
    doc_lines.append('"""')
    lines.append("    " + "\n    ".join(doc_lines))
    lines.append("")

    # Class variables
    lines.append(f'    _resource_type: ClassVar[str] = "{resource.full_type}"')
    lines.append("")

    if not resource.properties:
        lines.append("    pass")
        return "\n".join(lines)

    # Generate properties - all optional to avoid dataclass inheritance issues
    for prop in resource.properties:
        python_type = python_type_for_property(prop)

        # Check if type is a nested type from this service
        if prop.nested_type and prop.nested_type in nested_types:
            if prop.is_list:
                python_type = f"list[{prop.nested_type}]"
            elif prop.is_map:
                python_type = f"dict[str, {prop.nested_type}]"
            else:
                python_type = prop.nested_type

        # All fields are optional to avoid dataclass inheritance issues
        if python_type.startswith("list"):
            lines.append(
                f"    {prop.name}: {python_type} = field(default_factory=list)"
            )
        elif python_type.startswith("dict") and not python_type.startswith(
            "dict[str, Any]"
        ):
            lines.append(
                f"    {prop.name}: {python_type} = field(default_factory=dict)"
            )
        else:
            lines.append(f"    {prop.name}: {python_type} | None = None")

    # Generate attribute accessors if there are attributes
    if resource.attributes:
        lines.append("")
        lines.append("    # GetAtt attributes")
        for attr in resource.attributes:
            attr_const = attr.name.upper().replace("-", "_").replace(".", "_")
            lines.append(f'    {attr_const}: ClassVar[str] = "{attr.name}"')

    return "\n".join(lines)


def generate_service_module(
    service: str,
    resources: list[ResourceDef],
    nested_types: list[NestedTypeDef],
    cf_spec_version: str,
    service_enums: list[tuple[str, dict]] | None = None,
) -> str:
    """Generate a complete service module."""
    lines = []

    # Header
    lines.append(generate_file_header(service, cf_spec_version, GENERATOR_VERSION))

    # Collect nested type names for this service
    nested_type_names = {n.name for n in nested_types}

    # Generate enum constants first (single blank line between)
    enum_names = []
    if service_enums:
        lines.append("# Constants")
        lines.append("# " + "=" * 60)

        for enum_name, enum_data in sorted(service_enums, key=lambda x: x[0]):
            lines.append("")
            lines.append(generate_enum_class(enum_name, enum_data))
            enum_names.append(enum_name)
        lines.append("")

    # Generate nested types with deduplication
    # Track signatures to detect duplicates
    seen_signatures: dict[str, str] = {}  # signature -> first class name
    aliases: list[tuple[str, str]] = []  # (alias_name, original_name)

    if nested_types:
        lines.append("")
        lines.append("# Property Types")
        lines.append("# " + "=" * 60)

        for nested in sorted(nested_types, key=lambda n: n.name):
            sig = get_property_type_signature(nested)
            if sig and sig in seen_signatures:
                # Duplicate - create alias instead of full class
                aliases.append((nested.name, seen_signatures[sig]))
            else:
                lines.append("")
                lines.append(generate_property_type(nested))
                if sig:
                    seen_signatures[sig] = nested.name

        # Generate aliases for duplicates
        if aliases:
            lines.append("")
            lines.append("")
            lines.append("# Type aliases for duplicate property structures")
            for alias_name, original_name in sorted(aliases):
                lines.append(f"{alias_name} = {original_name}")
        lines.append("")

    # Generate resources (single blank line between)
    lines.append("")
    lines.append("# Resources")
    lines.append("# " + "=" * 60)

    for resource in sorted(resources, key=lambda r: r.name):
        lines.append("")
        lines.append(generate_resource_class(resource, nested_type_names))
    lines.append("")

    # Dynamic __all__ generation
    lines.append("")
    lines.append("# Export all public classes dynamically")
    lines.append("def _get_all():")
    lines.append("    import sys")
    lines.append("    return [")
    lines.append("        name for name, obj in vars(sys.modules[__name__]).items()")
    lines.append("        if isinstance(obj, type) and not name.startswith('_')")
    lines.append("    ]")
    lines.append("")
    lines.append("__all__ = _get_all()")

    return "\n".join(lines)


def generate_init_file(services: list[str], cf_spec_version: str) -> str:
    """Generate the resources/__init__.py file."""
    timestamp = datetime.now(UTC).strftime("%Y-%m-%dT%H:%M:%SZ")

    lines = [
        '"""',
        "AWS CloudFormation resource types.",
        "",
        "This package contains generated resource classes for all AWS services.",
        "",
        "Generated:",
        f"  Source: CloudFormation Spec {cf_spec_version}",
        f"  Generator: {GENERATOR_VERSION}",
        f"  Date: {timestamp}",
        '"""',
        "",
    ]

    # Import all services
    for service in sorted(services):
        lines.append(f"from wetwire_aws.resources import {service}")

    lines.append("")
    lines.append("__all__ = [")
    for service in sorted(services):
        lines.append(f'    "{service}",')
    lines.append("]")

    return "\n".join(lines)


def format_file(path: Path) -> bool:
    """Format a Python file using black."""
    try:
        result = subprocess.run(
            [sys.executable, "-m", "black", "--quiet", str(path)],
            capture_output=True,
        )
        return result.returncode == 0
    except Exception:
        return False


def generate(
    format_code: bool = True, dry_run: bool = False, include_enums: bool = True
) -> None:
    """
    Run the generate stage.

    Generates Python source files from the intermediate schema.
    """
    print("Stage 3: Generate")
    print("=" * 40)

    # Load intermediate schema
    parsed_path = SPECS_DIR / "parsed.json"
    if not parsed_path.exists():
        raise FileNotFoundError("parsed.json not found. Run parse first.")

    print(f"Loading {parsed_path}...")
    schema = IntermediateSchema.from_dict(json.loads(parsed_path.read_text()))

    # Group resources and nested types by service
    resources_by_service: dict[str, list[ResourceDef]] = defaultdict(list)
    nested_by_service: dict[str, list[NestedTypeDef]] = defaultdict(list)

    for resource in schema.resources:
        resources_by_service[resource.service].append(resource)

    for nested in schema.nested_types:
        nested_by_service[nested.service].append(nested)

    services = sorted(set(resources_by_service.keys()) | set(nested_by_service.keys()))
    print(f"Generating {len(services)} service modules...")

    # Load enums if available
    enums_by_service: dict[str, list[tuple[str, dict]]] = {}
    if include_enums:
        enums_path = SPECS_DIR / "enums.json"
        if enums_path.exists():
            print("Loading enum constants from botocore...")
            try:
                all_enums = json.loads(enums_path.read_text())
                # Validate enums file has expected structure
                if "services" not in all_enums:
                    print("  Warning: enums.json missing 'services' key")

                for service in services:
                    # Load all enums for the service
                    service_enums = load_enums_for_service(service)
                    if service_enums:
                        # Get all enums for this service
                        all_service_enums = get_all_enums_for_service(
                            service, service_enums
                        )
                        if all_service_enums:
                            enums_by_service[service] = all_service_enums
            except Exception as e:
                print(f"  Warning: Could not load enums: {e}")

    if dry_run:
        print("\nDry run - would generate:")
        for service in services:
            resource_count = len(resources_by_service.get(service, []))
            nested_count = len(nested_by_service.get(service, []))
            enum_count = len(enums_by_service.get(service, []))
            parts = [f"{resource_count} resources", f"{nested_count} property types"]
            if enum_count:
                parts.append(f"{enum_count} enums")
            print(f"  {service}: {', '.join(parts)}")
        return

    # Ensure resources directory exists
    RESOURCES_DIR.mkdir(parents=True, exist_ok=True)

    def generate_single_service(service: str) -> tuple[Path, int, int, int]:
        """Generate a single service module."""
        service_resources = resources_by_service.get(service, [])
        service_nested = nested_by_service.get(service, [])
        service_enums = enums_by_service.get(service)

        # Generate module content
        content = generate_service_module(
            service,
            service_resources,
            service_nested,
            schema.cf_spec_version,
            service_enums=service_enums,
        )

        # Write file
        service_dir = RESOURCES_DIR / service
        service_dir.mkdir(exist_ok=True)

        init_path = service_dir / "__init__.py"
        init_path.write_text(content)

        resource_count = len(service_resources)
        nested_count = len(service_nested)
        enum_count = len(service_enums) if service_enums else 0

        return init_path, resource_count, nested_count, enum_count

    # Generate service modules in parallel
    generated_files: list[Path] = []
    total_enums = 0

    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
        futures = {
            executor.submit(generate_single_service, svc): svc for svc in services
        }

        for future in as_completed(futures):
            service = futures[future]
            try:
                init_path, resource_count, nested_count, enum_count = future.result()
                generated_files.append(init_path)
                total_enums += enum_count

                parts = [
                    f"{resource_count} resources",
                    f"{nested_count} property types",
                ]
                if enum_count:
                    parts.append(f"{enum_count} enums")
                print(f"  {service}: {', '.join(parts)}")
            except Exception as e:
                print(f"  {service}: ERROR - {e}")

    # Generate main __init__.py (not parallelized - single file)
    init_content = generate_init_file(services, schema.cf_spec_version)
    init_path = RESOURCES_DIR / "__init__.py"
    init_path.write_text(init_content)
    generated_files.append(init_path)

    print(f"\nGenerated {len(generated_files)} files")
    if total_enums:
        print(f"  Including {total_enums} enum constant classes")

    # Format with black in parallel
    if format_code:
        print("\nFormatting with black...")
        with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
            results = list(executor.map(format_file, generated_files))
        formatted = sum(results)
        print(f"  Formatted {formatted}/{len(generated_files)} files")

    print(f"\nOutput written to {RESOURCES_DIR}")


def main():
    parser = argparse.ArgumentParser(
        description="Generate Python dataclasses from intermediate schema"
    )
    parser.add_argument(
        "--no-format", action="store_true", help="Skip black formatting"
    )
    parser.add_argument(
        "--no-enums", action="store_true", help="Skip enum constant generation"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be generated without writing",
    )
    args = parser.parse_args()

    try:
        generate(
            format_code=not args.no_format,
            dry_run=args.dry_run,
            include_enums=not args.no_enums,
        )
        print("\nGenerate completed successfully!")
    except Exception as e:
        print(f"\nGenerate failed: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
